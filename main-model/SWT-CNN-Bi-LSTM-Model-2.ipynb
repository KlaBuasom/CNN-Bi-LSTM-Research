{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client initialized successfully\n"
     ]
    }
   ],
   "source": [
    "#Setup Data\n",
    "apikey  = 'QHOA07WHc6ZkNS2A9i4bTcTbYuOpEqLI3eHu6iWp02gDOnmwMFpQsSQDO4nytISY'\n",
    "secret = 'yvHF7zGHB9CVj8cSHQb0j8cZdjhfNSdJ7FcWJuvIfVlNcCh4aT6UneTJRjcokzH9'\n",
    "\n",
    "from binance import Client, ThreadedWebsocketManager, ThreadedDepthCacheManager\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import warnings\n",
    "from termcolor import colored\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Autenticate\n",
    "client = Client(apikey, secret)\n",
    "print(\"Client initialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTCUSDT - 30m data is not available\n",
      "Attempting to retrieve BTCUSDT - 30m\n",
      "Requesting Complete\n",
      "Sorting Data columes...\n",
      "Preprocessing Data - Complete\n"
     ]
    }
   ],
   "source": [
    "#Chose to load a Historical Data\n",
    "\n",
    "import pywt\n",
    "def seconds_per_interval(interval: str) -> int:\n",
    "    seconds_per_unit = {\n",
    "        \"s\": 1,\n",
    "        \"m\": 60,\n",
    "        \"h\": 60 * 60,\n",
    "        \"d\": 24 * 60 * 60,\n",
    "        \"w\": 7 * 24 * 60 * 60,\n",
    "    }\n",
    "    try:\n",
    "        return int(interval[:-1]) * seconds_per_unit[interval[-1]] * 1000\n",
    "    except (ValueError, KeyError):\n",
    "        return None\n",
    "\n",
    "data_selections = input(\"Enter the data selection (e.g., BTCUSDT_15m): \")\n",
    "\n",
    "file_path = fr'C:\\Users\\DJKlaKunG\\Desktop\\Personal_Document\\GitHub\\CNN-Bi-LSTM-Research\\training-data\\SWT-CNN-Bi-LSTM-Model-2\\{data_selections}_data.csv'\n",
    "\n",
    "# Split the data_selections string into TICKET and interval\n",
    "TICKET, interval_str = data_selections.rsplit('_', 1)\n",
    "\n",
    "# Map the interval string to its corresponding KLINE_INTERVAL attribute\n",
    "interval_map = {\n",
    "    '1m': Client.KLINE_INTERVAL_1MINUTE,\n",
    "    '3m': Client.KLINE_INTERVAL_3MINUTE,\n",
    "    '5m': Client.KLINE_INTERVAL_5MINUTE,\n",
    "    '15m': Client.KLINE_INTERVAL_15MINUTE,\n",
    "    '30m': Client.KLINE_INTERVAL_30MINUTE,\n",
    "    '1h': Client.KLINE_INTERVAL_1HOUR,\n",
    "    '2h': Client.KLINE_INTERVAL_2HOUR,\n",
    "    '4h': Client.KLINE_INTERVAL_4HOUR,\n",
    "    '6h': Client.KLINE_INTERVAL_6HOUR,\n",
    "    '8h': Client.KLINE_INTERVAL_8HOUR,\n",
    "    '12h': Client.KLINE_INTERVAL_12HOUR,\n",
    "    '1d': Client.KLINE_INTERVAL_1DAY,\n",
    "    '3d': Client.KLINE_INTERVAL_3DAY,\n",
    "    '1w': Client.KLINE_INTERVAL_1WEEK,\n",
    "    '1M': Client.KLINE_INTERVAL_1MONTH,\n",
    "}\n",
    "\n",
    "KLINE_INTERVAL = interval_map.get(interval_str, None)\n",
    "if KLINE_INTERVAL is None:\n",
    "    print(f\"Invalid interval: {interval_str}\")\n",
    "else:\n",
    "    seconds = seconds_per_interval(KLINE_INTERVAL)\n",
    "    if seconds is None:\n",
    "        print(f\"Cannot convert interval '{KLINE_INTERVAL}' to milliseconds.\")\n",
    "\n",
    "    \n",
    "if os.path.exists(file_path):\n",
    "    print(\"Found Request file\")\n",
    "    print(f\"Requesting {TICKET} - {interval_str}\")\n",
    "    hist_df = pd.read_csv(file_path)\n",
    "    print(f\"Requesting {TICKET} - {interval_str} - Complete\")\n",
    "else:\n",
    "    print(f\"{TICKET} - {interval_str} data is not available\")\n",
    "    print(f\"Attempting to retrieve {TICKET} - {interval_str}\")\n",
    "    historical = client.get_historical_klines(TICKET, KLINE_INTERVAL, '1 Jan 2019')\n",
    "    print(f\"Requesting Complete\")\n",
    "    print(f\"Sorting Data columes...\")\n",
    "    hist_df = pd.DataFrame(historical)\n",
    "    hist_df.columns = ['Open Time', 'Open', 'High', 'Low', 'Close', 'Volume', 'Close Time', 'Quote Asset Volume', \n",
    "                        'Number of Trades', 'TB Base Volume', 'TB Quote Volume', 'Ignore']\n",
    "    \n",
    "    hist_df['Open Time'] = pd.to_datetime(hist_df['Open Time']/1000, unit='s')\n",
    "    hist_df['Close Time'] = pd.to_datetime(hist_df['Close Time']/1000, unit='s')\n",
    "    numeric_columns = ['Open', 'High', 'Low', 'Close', 'Volume', 'Quote Asset Volume', 'TB Base Volume', 'TB Quote Volume']\n",
    "    hist_df[numeric_columns] = hist_df[numeric_columns].apply(pd.to_numeric, axis=1)\n",
    "    hist_df['Gain'] = hist_df['Close'].diff().clip(lower=0)  # Positive differences only\n",
    "    hist_df['Loss'] = -hist_df['Close'].diff().clip(upper=0)  # Negative differences only, converted to positive values\n",
    "    hist_df['Close_T+1'] = hist_df['Close'].shift(-1)\n",
    "    \n",
    "    # Ensure the dataset length is even\n",
    "    hist_df = hist_df.iloc[:-1]\n",
    "    if len(hist_df) % 2 != 0:\n",
    "        hist_df = hist_df.iloc[:-1]\n",
    "\n",
    "    # Initialize the MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    features_to_transform = ['Open', 'High', 'Low', 'Close', 'Volume', 'Gain', 'Loss']\n",
    "    # Scale the features and store them in new columns\n",
    "    for feature in features_to_transform:\n",
    "        hist_df[f'{feature}_scaled'] = scaler.fit_transform(hist_df[[feature]])\n",
    "\n",
    "    # Fill any NaN values with 0 for the first row\n",
    "    hist_df.fillna(0, inplace=True)\n",
    "\n",
    "    features_scaled = ['Open_scaled', 'High_scaled', 'Low_scaled', 'Close_scaled', 'Volume_scaled', 'Gain_scaled', 'Loss_scaled']\n",
    "    \n",
    "    # Check if the data size is appropriate for 2 levels of decomposition\n",
    "    if len(hist_df) < 10:\n",
    "        print(\"Data size is too small for 2 levels of SWT decomposition with db2. Increase the dataset size.\")\n",
    "        # Optionally: exit or continue with other operations\n",
    "    else:\n",
    "        # Apply SWT with 'db2' wavelet and level=2, then store the results in new columns\n",
    "        for feature in features_scaled:\n",
    "            coeffs = pywt.swt(hist_df[feature], wavelet='db2', level=2, start_level=0)\n",
    "            \n",
    "            # For simplicity, we'll take the coefficients of both levels and store them\n",
    "            for level, (cA, cD) in enumerate(coeffs, 1):\n",
    "                hist_df[f'{feature}_SWT_level{level}_cA'] = cA\n",
    "                hist_df[f'{feature}_SWT_level{level}_cD'] = cD\n",
    "\n",
    "\n",
    "#Preprocessing Data\n",
    "hist_df.to_csv(file_path, index=False)\n",
    "print(\"Preprocessing Data - Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)        [(None, 5, 8)]               0         []                            \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)           (None, 3, 32)                800       ['input_9[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 3, 32)                128       ['conv1d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_36 (Dropout)        (None, 3, 32)                0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)           (None, 1, 64)                6208      ['dropout_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 1, 64)                256       ['conv1d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)        (None, 1, 64)                0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)       [(None, 5, 20)]              0         []                            \n",
      "                                                                                                  \n",
      " bidirectional_16 (Bidirect  (None, 1, 224)               158592    ['dropout_37[0][0]']          \n",
      " ional)                                                                                           \n",
      "                                                                                                  \n",
      " bidirectional_18 (Bidirect  (None, 5, 224)               119168    ['input_10[0][0]']            \n",
      " ional)                                                                                           \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)        (None, 1, 224)               0         ['bidirectional_16[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)        (None, 5, 224)               0         ['bidirectional_18[0][0]']    \n",
      "                                                                                                  \n",
      " bidirectional_17 (Bidirect  (None, 224)                  301952    ['dropout_38[0][0]']          \n",
      " ional)                                                                                           \n",
      "                                                                                                  \n",
      " bidirectional_19 (Bidirect  (None, 224)                  301952    ['dropout_41[0][0]']          \n",
      " ional)                                                                                           \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)        (None, 224)                  0         ['bidirectional_17[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_42 (Dropout)        (None, 224)                  0         ['bidirectional_19[0][0]']    \n",
      "                                                                                                  \n",
      " dense_28 (Dense)            (None, 56)                   12600     ['dropout_39[0][0]']          \n",
      "                                                                                                  \n",
      " dense_30 (Dense)            (None, 56)                   12600     ['dropout_42[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_40 (Dropout)        (None, 56)                   0         ['dense_28[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_43 (Dropout)        (None, 56)                   0         ['dense_30[0][0]']            \n",
      "                                                                                                  \n",
      " dense_29 (Dense)            (None, 28)                   1596      ['dropout_40[0][0]']          \n",
      "                                                                                                  \n",
      " dense_31 (Dense)            (None, 28)                   1596      ['dropout_43[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 56)                   0         ['dense_29[0][0]',            \n",
      " )                                                                   'dense_31[0][0]']            \n",
      "                                                                                                  \n",
      " dense_32 (Dense)            (None, 56)                   3192      ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)        (None, 56)                   0         ['dense_32[0][0]']            \n",
      "                                                                                                  \n",
      " dense_33 (Dense)            (None, 28)                   1596      ['dropout_44[0][0]']          \n",
      "                                                                                                  \n",
      " dense_34 (Dense)            (None, 4)                    116       ['dense_33[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 922352 (3.52 MB)\n",
      "Trainable params: 922160 (3.52 MB)\n",
      "Non-trainable params: 192 (768.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build Model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, Bidirectional, LSTM, Dense, Dropout, BatchNormalization, concatenate\n",
    "\n",
    "# Define Input for cA coefficients of Close, Open, High, Low\n",
    "input_cA = Input(shape=(LOOKBACK, 8))\n",
    "\n",
    "# CNN-Bi-LSTM Architecture for cA coefficients\n",
    "x1 = Conv1D(32, 3, activation='relu')(input_cA)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = Dropout(0.2)(x1)\n",
    "x1 = Conv1D(64, 3, activation='relu')(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = Dropout(0.2)(x1)\n",
    "x1 = Bidirectional(LSTM(112, return_sequences=True))(x1)\n",
    "x1 = Dropout(0.2)(x1)\n",
    "x1 = Bidirectional(LSTM(112, return_sequences=False))(x1)\n",
    "x1 = Dropout(0.2)(x1)\n",
    "x1 = Dense(56, activation='relu')(x1)\n",
    "x1 = Dropout(0.2)(x1)\n",
    "x1 = Dense(28, activation='relu')(x1)\n",
    "\n",
    "# Define Input for Volume, Gain, Loss, and cD coefficients\n",
    "input_others = Input(shape=(LOOKBACK, 20))\n",
    "\n",
    "# Bi-LSTM Architecture for the other coefficients\n",
    "x2 = Bidirectional(LSTM(112, return_sequences=True))(input_others)\n",
    "x2 = Dropout(0.2)(x2)\n",
    "x2 = Bidirectional(LSTM(112, return_sequences=False))(x2)\n",
    "x2 = Dropout(0.2)(x2)\n",
    "x2 = Dense(56, activation='relu')(x2)\n",
    "x2 = Dropout(0.2)(x2)\n",
    "x2 = Dense(28, activation='relu')(x2)\n",
    "\n",
    "# Merge the two models\n",
    "merged = concatenate([x1, x2])\n",
    "\n",
    "# Final dense layers after merging\n",
    "merged = Dense(56, activation='relu')(merged)\n",
    "merged = Dropout(0.2)(merged)\n",
    "merged = Dense(28, activation='relu')(merged)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(4, activation='linear')(merged)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input_cA, input_others], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
