{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#pip install python-binance\n",
    "#!pip install pandas\n",
    "#!pip install scikit-learn \n",
    "#!pip install PyWavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Data\n",
    "apikey  = 'QHOA07WHc6ZkNS2A9i4bTcTbYuOpEqLI3eHu6iWp02gDOnmwMFpQsSQDO4nytISY'\n",
    "secret = 'yvHF7zGHB9CVj8cSHQb0j8cZdjhfNSdJ7FcWJuvIfVlNcCh4aT6UneTJRjcokzH9'\n",
    "\n",
    "from binance import Client, ThreadedWebsocketManager, ThreadedDepthCacheManager\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import warnings\n",
    "from termcolor import colored\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Autenticate\n",
    "client = Client(apikey, secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requestin Old Data\n",
      "Requestin Old Data - Complete\n",
      "Preprocessing Data - Complete\n"
     ]
    }
   ],
   "source": [
    "#Historical Data\n",
    "file_path = r'C:\\Users\\DJKlaKunG\\Desktop\\Personal_Document\\GitHub\\CNN-Bi-LSTM-Research\\training-data\\hist_data.csv'\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(\"Requestin Old Data\")\n",
    "    hist_df = pd.read_csv(file_path)\n",
    "    print(\"Requestin Old Data - Complete\")\n",
    "else:\n",
    "    print(\"Requestin New Data\")\n",
    "    historical = client.get_historical_klines('BTCUSDT', Client.KLINE_INTERVAL_15MINUTE, '1 Jan 2019')\n",
    "    hist_df = pd.DataFrame(historical)\n",
    "    hist_df.columns = ['Open Time', 'Open', 'High', 'Low', 'Close', 'Volume', 'Close Time', 'Quote Asset Volume', \n",
    "                        'Number of Trades', 'TB Base Volume', 'TB Quote Volume', 'Ignore']\n",
    "    hist_df['Open Time'] = pd.to_datetime(hist_df['Open Time']/1000, unit='s')\n",
    "    hist_df['Close Time'] = pd.to_datetime(hist_df['Close Time']/1000, unit='s')\n",
    "    numeric_columns = ['Open', 'High', 'Low', 'Close', 'Volume', 'Quote Asset Volume', 'TB Base Volume', 'TB Quote Volume']\n",
    "    hist_df[numeric_columns] = hist_df[numeric_columns].apply(pd.to_numeric, axis=1)\n",
    "    print(\"Requestin New Data - Complete\")\n",
    "\n",
    "\n",
    "#Preprocessing Data\n",
    "hist_df.to_csv(file_path, index=False)\n",
    "print(\"Preprocessing Data - Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate Necessary data - Complete\n"
     ]
    }
   ],
   "source": [
    "#Calculate the Nessary Value then appear in the CSV file\n",
    "warnings.filterwarnings('ignore')\n",
    "# 1. Calculate Gain and Loss\n",
    "hist_df['Gain'] = hist_df['Close'].diff().apply(lambda x: x if x > 0 else 0)\n",
    "hist_df['Loss'] = hist_df['Close'].diff().apply(lambda x: -x if x < 0 else 0)\n",
    "\n",
    "# 2. Calculate Average Gain and Average Loss for the last 14 bars\n",
    "hist_df['Avg_Gain_14'] = hist_df['Gain'].rolling(window=14).mean()\n",
    "hist_df['Avg_Loss_14'] = hist_df['Loss'].rolling(window=14).mean()\n",
    "\n",
    "# 3. Calculate ADX for 7 bars\n",
    "# First, we need to calculate the True Range, +DM, and -DM\n",
    "hist_df['HL'] = hist_df['High'] - hist_df['Low']\n",
    "hist_df['HPC'] = (hist_df['High'] - hist_df['Close']).shift(1)\n",
    "hist_df['LPC'] = (hist_df['Close'].shift(1) - hist_df['Low'])\n",
    "\n",
    "# True Range\n",
    "hist_df['TR'] = hist_df[['HL', 'HPC', 'LPC']].max(axis=1)\n",
    "\n",
    "# Positive Directional Movement (+DM) and Negative Directional Movement (-DM)\n",
    "hist_df['+DM'] = ((hist_df['High'] - hist_df['High'].shift(1)) > \n",
    "                 (hist_df['Low'].shift(1) - hist_df['Low'])).astype(int) * hist_df['HL']\n",
    "hist_df['-DM'] = ((hist_df['Low'].shift(1) - hist_df['Low']) > \n",
    "                 (hist_df['High'] - hist_df['High'].shift(1))).astype(int) * hist_df['HL']\n",
    "\n",
    "# Smoothed True Range and Directional Movements\n",
    "hist_df['Smoothed_TR'] = hist_df['TR'].rolling(window=7).sum()\n",
    "hist_df['Smoothed_+DM'] = hist_df['+DM'].rolling(window=7).sum()\n",
    "hist_df['Smoothed_-DM'] = hist_df['-DM'].rolling(window=7).sum()\n",
    "\n",
    "# Directional Indicators\n",
    "hist_df['+DI'] = 100 * hist_df['Smoothed_+DM'] / hist_df['Smoothed_TR']\n",
    "hist_df['-DI'] = 100 * hist_df['Smoothed_-DM'] / hist_df['Smoothed_TR']\n",
    "\n",
    "# DX (Directional Movement Index)\n",
    "hist_df['DX'] = 100 * (hist_df['+DI'] - hist_df['-DI']).abs() / (hist_df['+DI'] + hist_df['-DI'])\n",
    "\n",
    "# ADX (Average Directional Index)\n",
    "hist_df['ADX_7'] = hist_df['DX'].rolling(window=7).mean()\n",
    "\n",
    "# 4. Calculate EMA for 7 bars\n",
    "hist_df['EMA_7'] = hist_df['Close'].ewm(span=7, adjust=False).mean()\n",
    "\n",
    "# Drop intermediate columns used for calculations\n",
    "drop_cols = ['HL', 'HPC', 'LPC', 'TR', '+DM', '-DM', 'Smoothed_TR', 'Smoothed_+DM', 'Smoothed_-DM', '+DI', '-DI', 'DX']\n",
    "hist_df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "# Save the dataframe with calculated values to the specified file path\n",
    "hist_df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"Calculate Necessary data - Complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate Necessary data - Complete\n"
     ]
    }
   ],
   "source": [
    "#Calculate the Stationary Wavelet Transform (SWT)\n",
    "import pywt\n",
    "#Redefine the list of columns to transform\n",
    "columns_to_transform = ['Close', 'Gain', 'Loss', 'EMA_7','ADX_7']\n",
    "\n",
    "# Define the Fourier Transformation function again\n",
    "def apply_swt(series):\n",
    "    # Apply Stationary Wavelet Transform (SWT) to the series\n",
    "    coeffs = pywt.swt(series, wavelet='db1', level=1)\n",
    "    # We'll use the approximation coefficients for our analysis\n",
    "    return coeffs[0][0]\n",
    "\n",
    "# Apply SWT to the specified columns in the dataset\n",
    "for col in columns_to_transform:\n",
    "    hist_df[f'{col}_SWT'] = apply_swt(hist_df[col])\n",
    "\n",
    "# Save the dataframe with calculated values to the specified file path\n",
    "hist_df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"Calculate Necessary data - Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting New parameters - Complete\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameters #Parameters Settings\n",
    "SEQUENCE_LENGTH = 15\n",
    "LOOKBACK = 14\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001\n",
    "KERNEL_SIZE = 3\n",
    "FILTERS = 64\n",
    "POOL_SIZE = 2\n",
    "LSTM_UNITS1 = 50\n",
    "LSTM_UNITS2 = 50\n",
    "TEST_SIZE = 0.1\n",
    "ACTIVATION_FUNC = 'relu'\n",
    "LOSS_FUNC = 'mean_squared_error'\n",
    "PERFORMANCE_METRIC = RootMeanSquaredError(name='rmse')\n",
    "\n",
    "print(\"Setting New parameters - Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((146925, 14, 1), (16326, 14, 1))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Preparation: Shape the data into appropriate sequences for time series forecasting.\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select the transformed Close price as our feature\n",
    "feature_column = 'Close_SWT'\n",
    "target_column = 'Close_SWT'\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(hist_df[[feature_column]])\n",
    "\n",
    "# Create sequences of length 15 (14 features + 1 target)\n",
    "X, y = [], []\n",
    "\n",
    "for i in range(len(scaled_data) - SEQUENCE_LENGTH):\n",
    "    X.append(scaled_data[i:i+SEQUENCE_LENGTH-1])\n",
    "    y.append(scaled_data[i+SEQUENCE_LENGTH-1])\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "# Split the data into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=42)\n",
    "\n",
    "# Reshape the input to be [samples, time steps, features] which is required for LSTM\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 12, 64)            256       \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPoolin  (None, 6, 64)             0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirecti  (None, 6, 100)            46000     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirecti  (None, 100)               60400     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106757 (417.02 KB)\n",
      "Trainable params: 106757 (417.02 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the CNN-Bi-LSTM Model:\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "\n",
    "\n",
    "# Modified model with an additional CNN layer\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# First CNN layer\n",
    "model.add(Conv1D(filters=FILTERS, kernel_size=KERNEL_SIZE, activation=ACTIVATION_FUNC, input_shape=(LOOKBACK, 1)))\n",
    "model.add(MaxPooling1D(pool_size=POOL_SIZE))\n",
    "\n",
    "# Bi-LSTM layers\n",
    "model.add(Bidirectional(LSTM(LSTM_UNITS1, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(LSTM_UNITS2)))\n",
    "\n",
    "# Dense layer for prediction\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss=LOSS_FUNC, metrics=[PERFORMANCE_METRIC])\n",
    "\n",
    "# Display the modified model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training In Progress...\n",
      "Epoch 1/100\n",
      "574/574 [==============================] - 11s 15ms/step - loss: 0.0018 - rmse: 0.0423 - val_loss: 1.6003e-05 - val_rmse: 0.0040\n",
      "Epoch 2/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 1.5449e-05 - rmse: 0.0039 - val_loss: 1.5254e-05 - val_rmse: 0.0039\n",
      "Epoch 3/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 1.5336e-05 - rmse: 0.0039 - val_loss: 1.4960e-05 - val_rmse: 0.0039\n",
      "Epoch 4/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 1.5409e-05 - rmse: 0.0039 - val_loss: 1.5749e-05 - val_rmse: 0.0040\n",
      "Epoch 5/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 1.5217e-05 - rmse: 0.0039 - val_loss: 1.3118e-05 - val_rmse: 0.0036\n",
      "Epoch 6/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 1.5972e-05 - rmse: 0.0040 - val_loss: 1.8088e-05 - val_rmse: 0.0043\n",
      "Epoch 7/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 1.7542e-05 - rmse: 0.0042 - val_loss: 1.6487e-05 - val_rmse: 0.0041\n",
      "Epoch 8/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 1.9591e-05 - rmse: 0.0044 - val_loss: 1.6283e-05 - val_rmse: 0.0040\n",
      "Epoch 9/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 1.7277e-05 - rmse: 0.0042 - val_loss: 3.4007e-05 - val_rmse: 0.0058\n",
      "Epoch 10/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 1.5784e-05 - rmse: 0.0040 - val_loss: 2.4964e-05 - val_rmse: 0.0050\n",
      "Epoch 11/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 1.7550e-05 - rmse: 0.0042 - val_loss: 2.4790e-05 - val_rmse: 0.0050\n",
      "Epoch 12/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 1.5431e-05 - rmse: 0.0039 - val_loss: 1.1002e-05 - val_rmse: 0.0033\n",
      "Epoch 13/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 1.4655e-05 - rmse: 0.0038 - val_loss: 1.1785e-05 - val_rmse: 0.0034\n",
      "Epoch 14/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 1.3455e-05 - rmse: 0.0037 - val_loss: 1.0938e-05 - val_rmse: 0.0033\n",
      "Epoch 15/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 1.3266e-05 - rmse: 0.0036 - val_loss: 7.5712e-06 - val_rmse: 0.0028\n",
      "Epoch 16/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 1.2693e-05 - rmse: 0.0036 - val_loss: 6.9739e-06 - val_rmse: 0.0026\n",
      "Epoch 17/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 1.3374e-05 - rmse: 0.0037 - val_loss: 1.5112e-05 - val_rmse: 0.0039\n",
      "Epoch 18/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 1.0749e-05 - rmse: 0.0033 - val_loss: 1.2907e-05 - val_rmse: 0.0036\n",
      "Epoch 19/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 9.6958e-06 - rmse: 0.0031 - val_loss: 7.2885e-06 - val_rmse: 0.0027\n",
      "Epoch 20/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 8.8093e-06 - rmse: 0.0030 - val_loss: 7.5960e-06 - val_rmse: 0.0028\n",
      "Epoch 21/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 9.7598e-06 - rmse: 0.0031 - val_loss: 5.4254e-06 - val_rmse: 0.0023\n",
      "Epoch 22/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 6.7102e-06 - rmse: 0.0026 - val_loss: 5.0717e-06 - val_rmse: 0.0023\n",
      "Epoch 23/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 6.4276e-06 - rmse: 0.0025 - val_loss: 1.0123e-05 - val_rmse: 0.0032\n",
      "Epoch 24/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 7.5544e-06 - rmse: 0.0027 - val_loss: 4.8930e-06 - val_rmse: 0.0022\n",
      "Epoch 25/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 5.9219e-06 - rmse: 0.0024 - val_loss: 3.3683e-06 - val_rmse: 0.0018\n",
      "Epoch 26/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 6.1752e-06 - rmse: 0.0025 - val_loss: 2.8571e-06 - val_rmse: 0.0017\n",
      "Epoch 27/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 5.7233e-06 - rmse: 0.0024 - val_loss: 8.6605e-06 - val_rmse: 0.0029\n",
      "Epoch 28/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 6.4099e-06 - rmse: 0.0025 - val_loss: 9.2086e-06 - val_rmse: 0.0030\n",
      "Epoch 29/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 5.3098e-06 - rmse: 0.0023 - val_loss: 2.6970e-06 - val_rmse: 0.0016\n",
      "Epoch 30/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 5.1871e-06 - rmse: 0.0023 - val_loss: 1.2853e-05 - val_rmse: 0.0036\n",
      "Epoch 31/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 5.0949e-06 - rmse: 0.0023 - val_loss: 2.4308e-06 - val_rmse: 0.0016\n",
      "Epoch 32/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 5.2668e-06 - rmse: 0.0023 - val_loss: 2.5911e-06 - val_rmse: 0.0016\n",
      "Epoch 33/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 4.1706e-06 - rmse: 0.0020 - val_loss: 2.3968e-06 - val_rmse: 0.0015\n",
      "Epoch 34/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 5.0515e-06 - rmse: 0.0022 - val_loss: 3.1103e-06 - val_rmse: 0.0018\n",
      "Epoch 35/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 4.9700e-06 - rmse: 0.0022 - val_loss: 3.5738e-06 - val_rmse: 0.0019\n",
      "Epoch 36/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 4.4702e-06 - rmse: 0.0021 - val_loss: 2.5005e-06 - val_rmse: 0.0016\n",
      "Epoch 37/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 4.6284e-06 - rmse: 0.0022 - val_loss: 2.7542e-06 - val_rmse: 0.0017\n",
      "Epoch 38/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 4.3001e-06 - rmse: 0.0021 - val_loss: 1.6164e-05 - val_rmse: 0.0040\n",
      "Epoch 39/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 4.6868e-06 - rmse: 0.0022 - val_loss: 4.6140e-06 - val_rmse: 0.0021\n",
      "Epoch 40/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 4.5090e-06 - rmse: 0.0021 - val_loss: 3.2573e-06 - val_rmse: 0.0018\n",
      "Epoch 41/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 4.8186e-06 - rmse: 0.0022 - val_loss: 2.8851e-06 - val_rmse: 0.0017\n",
      "Epoch 42/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 4.5204e-06 - rmse: 0.0021 - val_loss: 2.6258e-06 - val_rmse: 0.0016\n",
      "Epoch 43/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 4.0483e-06 - rmse: 0.0020 - val_loss: 2.2941e-06 - val_rmse: 0.0015\n",
      "Epoch 44/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 4.1586e-06 - rmse: 0.0020 - val_loss: 2.2162e-06 - val_rmse: 0.0015\n",
      "Epoch 45/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 4.4026e-06 - rmse: 0.0021 - val_loss: 2.5205e-06 - val_rmse: 0.0016\n",
      "Epoch 46/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 3.8492e-06 - rmse: 0.0020 - val_loss: 3.0195e-06 - val_rmse: 0.0017\n",
      "Epoch 47/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 4.3181e-06 - rmse: 0.0021 - val_loss: 4.4829e-06 - val_rmse: 0.0021\n",
      "Epoch 48/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 4.5082e-06 - rmse: 0.0021 - val_loss: 6.3641e-06 - val_rmse: 0.0025\n",
      "Epoch 49/100\n",
      "574/574 [==============================] - 9s 15ms/step - loss: 3.7410e-06 - rmse: 0.0019 - val_loss: 6.2049e-06 - val_rmse: 0.0025\n",
      "Epoch 50/100\n",
      "574/574 [==============================] - 9s 15ms/step - loss: 3.7932e-06 - rmse: 0.0019 - val_loss: 5.3835e-06 - val_rmse: 0.0023\n",
      "Epoch 51/100\n",
      "574/574 [==============================] - 9s 15ms/step - loss: 3.9409e-06 - rmse: 0.0020 - val_loss: 2.1329e-06 - val_rmse: 0.0015\n",
      "Epoch 52/100\n",
      "574/574 [==============================] - 9s 15ms/step - loss: 4.1264e-06 - rmse: 0.0020 - val_loss: 3.7943e-06 - val_rmse: 0.0019\n",
      "Epoch 53/100\n",
      "574/574 [==============================] - 9s 15ms/step - loss: 3.6550e-06 - rmse: 0.0019 - val_loss: 8.9866e-06 - val_rmse: 0.0030\n",
      "Epoch 54/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 3.8086e-06 - rmse: 0.0020 - val_loss: 2.3719e-06 - val_rmse: 0.0015\n",
      "Epoch 55/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 3.8557e-06 - rmse: 0.0020 - val_loss: 2.4744e-06 - val_rmse: 0.0016\n",
      "Epoch 56/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 4.2146e-06 - rmse: 0.0021 - val_loss: 2.7222e-06 - val_rmse: 0.0016\n",
      "Epoch 57/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 3.3846e-06 - rmse: 0.0018 - val_loss: 4.8153e-06 - val_rmse: 0.0022\n",
      "Epoch 58/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 3.2120e-06 - rmse: 0.0018 - val_loss: 5.6417e-06 - val_rmse: 0.0024\n",
      "Epoch 59/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 4.3180e-06 - rmse: 0.0021 - val_loss: 3.7412e-06 - val_rmse: 0.0019\n",
      "Epoch 60/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 3.2938e-06 - rmse: 0.0018 - val_loss: 2.0581e-06 - val_rmse: 0.0014\n",
      "Epoch 61/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 3.5405e-06 - rmse: 0.0019 - val_loss: 5.8683e-06 - val_rmse: 0.0024\n",
      "Epoch 62/100\n",
      "574/574 [==============================] - 9s 15ms/step - loss: 3.3676e-06 - rmse: 0.0018 - val_loss: 3.6097e-06 - val_rmse: 0.0019\n",
      "Epoch 63/100\n",
      "574/574 [==============================] - 9s 16ms/step - loss: 3.1575e-06 - rmse: 0.0018 - val_loss: 2.1759e-06 - val_rmse: 0.0015\n",
      "Epoch 64/100\n",
      "574/574 [==============================] - 9s 16ms/step - loss: 3.2281e-06 - rmse: 0.0018 - val_loss: 2.5862e-06 - val_rmse: 0.0016\n",
      "Epoch 65/100\n",
      "574/574 [==============================] - 8s 15ms/step - loss: 3.5735e-06 - rmse: 0.0019 - val_loss: 8.6827e-06 - val_rmse: 0.0029\n",
      "Epoch 66/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 3.3207e-06 - rmse: 0.0018 - val_loss: 1.8275e-06 - val_rmse: 0.0014\n",
      "Epoch 67/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 3.0718e-06 - rmse: 0.0018 - val_loss: 2.3256e-06 - val_rmse: 0.0015\n",
      "Epoch 68/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 3.4582e-06 - rmse: 0.0019 - val_loss: 2.2070e-06 - val_rmse: 0.0015\n",
      "Epoch 69/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 3.3582e-06 - rmse: 0.0018 - val_loss: 1.8975e-06 - val_rmse: 0.0014\n",
      "Epoch 70/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 3.0483e-06 - rmse: 0.0017 - val_loss: 2.2765e-06 - val_rmse: 0.0015\n",
      "Epoch 71/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 3.3464e-06 - rmse: 0.0018 - val_loss: 1.7600e-06 - val_rmse: 0.0013\n",
      "Epoch 72/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 3.3424e-06 - rmse: 0.0018 - val_loss: 1.9984e-06 - val_rmse: 0.0014\n",
      "Epoch 73/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 3.6620e-06 - rmse: 0.0019 - val_loss: 2.6402e-06 - val_rmse: 0.0016\n",
      "Epoch 74/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 2.8055e-06 - rmse: 0.0017 - val_loss: 1.7702e-06 - val_rmse: 0.0013\n",
      "Epoch 75/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 3.0588e-06 - rmse: 0.0017 - val_loss: 1.7473e-06 - val_rmse: 0.0013\n",
      "Epoch 76/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 3.5924e-06 - rmse: 0.0019 - val_loss: 4.2258e-06 - val_rmse: 0.0021\n",
      "Epoch 77/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 2.9892e-06 - rmse: 0.0017 - val_loss: 3.3974e-06 - val_rmse: 0.0018\n",
      "Epoch 78/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 3.1567e-06 - rmse: 0.0018 - val_loss: 1.7272e-06 - val_rmse: 0.0013\n",
      "Epoch 79/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 2.8328e-06 - rmse: 0.0017 - val_loss: 2.1255e-06 - val_rmse: 0.0015\n",
      "Epoch 80/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 2.9256e-06 - rmse: 0.0017 - val_loss: 2.9448e-06 - val_rmse: 0.0017\n",
      "Epoch 81/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 3.3183e-06 - rmse: 0.0018 - val_loss: 1.9432e-06 - val_rmse: 0.0014\n",
      "Epoch 82/100\n",
      "574/574 [==============================] - 8s 15ms/step - loss: 2.7655e-06 - rmse: 0.0017 - val_loss: 2.1183e-06 - val_rmse: 0.0015\n",
      "Epoch 83/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 3.1506e-06 - rmse: 0.0018 - val_loss: 1.7270e-06 - val_rmse: 0.0013\n",
      "Epoch 84/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 3.0557e-06 - rmse: 0.0017 - val_loss: 5.1295e-06 - val_rmse: 0.0023\n",
      "Epoch 85/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 2.8597e-06 - rmse: 0.0017 - val_loss: 2.2470e-06 - val_rmse: 0.0015\n",
      "Epoch 86/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 2.7405e-06 - rmse: 0.0017 - val_loss: 2.5337e-06 - val_rmse: 0.0016\n",
      "Epoch 87/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 2.8322e-06 - rmse: 0.0017 - val_loss: 6.3398e-06 - val_rmse: 0.0025\n",
      "Epoch 88/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 2.9027e-06 - rmse: 0.0017 - val_loss: 3.9193e-06 - val_rmse: 0.0020\n",
      "Epoch 89/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 2.8549e-06 - rmse: 0.0017 - val_loss: 1.8762e-06 - val_rmse: 0.0014\n",
      "Epoch 90/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 2.6223e-06 - rmse: 0.0016 - val_loss: 5.6981e-06 - val_rmse: 0.0024\n",
      "Epoch 91/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 2.7766e-06 - rmse: 0.0017 - val_loss: 1.6379e-06 - val_rmse: 0.0013\n",
      "Epoch 92/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 2.9110e-06 - rmse: 0.0017 - val_loss: 2.5351e-06 - val_rmse: 0.0016\n",
      "Epoch 93/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 2.6942e-06 - rmse: 0.0016 - val_loss: 2.0613e-06 - val_rmse: 0.0014\n",
      "Epoch 94/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 2.6471e-06 - rmse: 0.0016 - val_loss: 2.8763e-06 - val_rmse: 0.0017\n",
      "Epoch 95/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 3.0271e-06 - rmse: 0.0017 - val_loss: 1.8614e-06 - val_rmse: 0.0014\n",
      "Epoch 96/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 2.9285e-06 - rmse: 0.0017 - val_loss: 1.5733e-06 - val_rmse: 0.0013\n",
      "Epoch 97/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 2.6207e-06 - rmse: 0.0016 - val_loss: 2.3536e-06 - val_rmse: 0.0015\n",
      "Epoch 98/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 2.8324e-06 - rmse: 0.0017 - val_loss: 2.8017e-06 - val_rmse: 0.0017\n",
      "Epoch 99/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 2.5578e-06 - rmse: 0.0016 - val_loss: 3.7122e-06 - val_rmse: 0.0019\n",
      "Epoch 100/100\n",
      "574/574 [==============================] - 8s 14ms/step - loss: 2.4768e-06 - rmse: 0.0016 - val_loss: 5.7335e-06 - val_rmse: 0.0024\n",
      "\n",
      "Training Completed!\n",
      "Total Training Time: 814.77 seconds\n",
      "Average Time Per Step: 0.0142 seconds\n"
     ]
    }
   ],
   "source": [
    "#Training In Progress..\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"Training In Progress...\")\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate total training time and average time per step\n",
    "total_time = end_time - start_time\n",
    "avg_time_per_step = total_time / (len(X_train) // BATCH_SIZE * EPOCHS)  # Using '//' for integer division\n",
    "\n",
    "print(\"\\nTraining Completed!\")\n",
    "print(f\"Total Training Time: {total_time:.2f} seconds\")\n",
    "print(f\"Average Time Per Step: {avg_time_per_step:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4592/4592 [==============================] - 7s 1ms/step\n",
      "511/511 [==============================] - 1s 1ms/step\n",
      "Model Performance Evaluation:\n",
      "------------------------------\n",
      "Training RMSE: 0.00240532\n",
      "Validation RMSE: 0.00239448\n",
      "----------------------------------------\n",
      "Reconstructed Model Performance Evaluation:\n",
      "----------------------------------------\n",
      "Training RMSE: 221.82928277\n",
      "Validation RMSE: 220.82902453\n"
     ]
    }
   ],
   "source": [
    "#Model Evaluation\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Predicting the values for training and validation datasets\n",
    "train_predictions = model.predict(X_train)\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Compute RMSE for training data\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, train_predictions))\n",
    "\n",
    "# Compute RMSE for validation data\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
    "\n",
    "train_rmse, test_rmse\n",
    "\n",
    "# Reconstruct the predictions and actual values to the original domain\n",
    "reconstructed_train_preds = scaler.inverse_transform(train_predictions)\n",
    "reconstructed_test_preds = scaler.inverse_transform(test_predictions)\n",
    "actual_train_values = scaler.inverse_transform(y_train)\n",
    "actual_test_values = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Compute RMSE for the reconstructed values\n",
    "reconstructed_train_rmse = np.sqrt(mean_squared_error(actual_train_values, reconstructed_train_preds))\n",
    "reconstructed_test_rmse = np.sqrt(mean_squared_error(actual_test_values, reconstructed_test_preds))\n",
    "\n",
    "print(\"Model Performance Evaluation:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Training RMSE: {train_rmse:.8f}\")\n",
    "print(f\"Validation RMSE: {test_rmse:.8f}\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Reconstructed Model Performance Evaluation:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Training RMSE: {reconstructed_train_rmse:.8f}\")\n",
    "print(f\"Validation RMSE: {reconstructed_test_rmse:.8f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save - Complete Model_0001\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Step 1: Check if the CSV file exists and determine MODEL_NAME\n",
    "if os.path.exists(save_path):\n",
    "    existing_data = pd.read_csv(save_path)\n",
    "    model_number = len(existing_data) + 1\n",
    "    MODEL_NAME = f\"Model_{model_number:04d}\"  # Format the model number with leading zeros\n",
    "else:\n",
    "    MODEL_NAME = \"Model_0001\"\n",
    "\n",
    "# Update the model_path with the new MODEL_NAME\n",
    "model_path = r\"C:\\Users\\DJKlaKunG\\Desktop\\Personal_Document\\GitHub\\CNN-Bi-LSTM-Research\\model-data\\\\\" + MODEL_NAME + \".h5\"\n",
    "# Save the model (assuming the model is already trained)\n",
    "model.save(model_path)\n",
    "\n",
    "\n",
    "data_dict = {\n",
    "    \"MODEL_NAME\": [MODEL_NAME],\n",
    "    \"SEQUENCE_LENGTH\": [SEQUENCE_LENGTH],\n",
    "    \"LOOKBACK\": [LOOKBACK],\n",
    "    \"EPOCHS\": [EPOCHS],\n",
    "    \"BATCH_SIZE\": [BATCH_SIZE],\n",
    "    \"LEARNING_RATE\": [LEARNING_RATE],\n",
    "    \"KERNEL_SIZE\": [KERNEL_SIZE],\n",
    "    \"FILTERS\": [FILTERS],\n",
    "    \"POOL_SIZE\": [POOL_SIZE],\n",
    "    \"LSTM_UNITS1\": [LSTM_UNITS1],\n",
    "    \"LSTM_UNITS2\": [LSTM_UNITS2],\n",
    "    \"ACTIVATION_FUNC\": [ACTIVATION_FUNC],\n",
    "    \"LOSS_FUNC\": [LOSS_FUNC],\n",
    "    \"PERFORMANCE_METRIC\": [str(PERFORMANCE_METRIC)],  # Convert metric to string for saving\n",
    "    \"TOTAL_TIME\": [total_time],\n",
    "    \"AVG_TIME_PER_STEP\": [avg_time_per_step],\n",
    "    \"TRAIN_RMSE\": [train_rmse],\n",
    "    \"TEST_RMSE\": [test_rmse],\n",
    "    \"RECONSTRUCTED_TRAIN_RMSE\": [reconstructed_train_rmse],\n",
    "    \"RECONSTRUCTED_TEST_RMSE\": [reconstructed_test_rmse],\n",
    "    \"TEST_SIZE\": [TEST_SIZE]\n",
    "}\n",
    "\n",
    "# Convert dictionary into a DataFrame\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "# Check if the CSV file exists and save data\n",
    "if os.path.exists(save_path):\n",
    "    df.to_csv(save_path, mode='a', header=False, index=False)  # Append data without header\n",
    "else:\n",
    "    df.to_csv(save_path, index=False)  # Save new file with header\n",
    "\n",
    "# Display the generated MODEL_NAME for verification\n",
    "\n",
    "\n",
    "print(\"Save - Complete \" + MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
